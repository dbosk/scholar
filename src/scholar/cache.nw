\chapter{Caching}
\label{cache-module}

\section{Introduction}

When conducting systematic literature reviews, researchers often run the same
search multiple times---refining queries, re-running reports, or continuing
work across sessions.
Each search hits external APIs that impose rate limits and add latency.
Caching search results provides two key benefits:
\begin{description}
\item[API rate limit management] Many academic databases impose strict rate
  limits. Caching avoids redundant requests when refining searches or
  re-running reports.
\item[Reproducibility] Cached results ensure that re-running a search produces
  identical results, supporting systematic review methodology.
\end{description}

\section{Design overview}

We implement caching using the [[cachetools]] library with the [[@cached]]
decorator.
Each provider maintains its own cache dictionary, which we persist to disk
using [[pickle]].
The cache never expires automatically---users clear it manually when they want
fresh results.

The cache files are stored in a platform-appropriate location:
\begin{itemize}
\item Linux: [[~/.cache/scholar/]]
\item macOS: [[~/Library/Caches/scholar/]]
\item Windows: [[C:\Users\<user>\AppData\Local\scholar\Cache\]]
\end{itemize}

<<[[cache.py]]>>=
"""
Cache management for Scholar search providers.

Provides persistent caching of search results to avoid redundant API calls.
Cache is stored as pickled dictionaries, one per provider.
"""

<<imports>>
<<constants>>
<<cache directory functions>>
<<cache load and save functions>>
<<cache management functions>>
<<atexit registration>>
@


\section{Testing}
\label{sec:testing}

Tests are distributed throughout this document, appearing after each
implementation section they verify.
The test file collects all distributed test chunks:

<<test [[cache.py]]>>=
"""Tests for the cache module."""
import os
import pytest
from pathlib import Path
from unittest.mock import patch

from scholar.cache import *
from scholar import *


<<test functions>>
@


\section{Cache directory management}

We use [[platformdirs]] to determine the appropriate cache directory for each
operating system.
This follows platform conventions and allows users to find and manage the cache
easily.

<<imports>>=
import os
from pathlib import Path
import platformdirs
@

<<cache directory functions>>=
def get_cache_dir() -> Path:
    """
    Return the platform-appropriate cache directory for Scholar.

    The directory is created if it doesn't exist.
    Can be overridden with SCHOLAR_CACHE_DIR environment variable.
    """
    cache_dir = os.environ.get("SCHOLAR_CACHE_DIR")
    if cache_dir:
        path = Path(cache_dir)
    else:
        path = Path(platformdirs.user_cache_dir("scholar"))
    path.mkdir(parents=True, exist_ok=True)
    return path
@

\subsection{Testing cache directory}

The cache directory should be created if it doesn't exist, and should respect
the environment variable override.

<<test functions>>=
class TestGetCacheDir:
    """Tests for get_cache_dir function."""

    def test_creates_directory(self, tmp_path, monkeypatch):
        """Cache directory is created if it doesn't exist."""
        cache_dir = tmp_path / "scholar_cache"
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(cache_dir))
        result = get_cache_dir()
        assert result == cache_dir
        assert cache_dir.exists()

    def test_respects_environment_variable(self, tmp_path, monkeypatch):
        """SCHOLAR_CACHE_DIR overrides default location."""
        custom_dir = tmp_path / "custom"
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(custom_dir))
        result = get_cache_dir()
        assert result == custom_dir
@


\section{Loading and saving caches}
\label{sec:cache-load-save}

Each provider has its own cache file, named after the provider.
We use Python's native binary serialization because it handles the [[Paper]]
dataclass objects without any additional configuration.

\subsection{Why Not JSON?}

We considered JSON for human-readable cache files, but chose binary
serialization because:
\begin{description}
\item[Dataclass support] Binary format handles [[Paper]] objects natively.
  JSON would require custom encoder/decoder classes.
\item[Type preservation] Binary format preserves Python types (datetime, etc.)
  exactly. JSON would require type annotations or conventions.
\item[Simplicity] No need to maintain JSON schemas as data structures evolve.
\end{description}

The tradeoff is that cache files aren't human-readable, but since they're
only for performance optimization (not user data), this is acceptable.
User-generated content (notes) uses JSON for the opposite reasons.

\subsection{Atomic Writes (Not Implemented)}

Ideally, we'd use atomic writes (write to temp file, then rename) to
prevent corruption during crashes. For simplicity, we write directly.
The worst case is a corrupted cache file, which just means a cache miss---the
[[load_cache]] function gracefully returns an empty dictionary.

\section{Dependencies}

<<imports>>=
import pickle
from typing import Any
@

\subsection{Graceful Degradation}

When loading a cache, we return an empty dictionary if the file doesn't
exist or is corrupted.
This ensures the application continues working even if cache files are damaged.

<<cache load and save functions>>=
def load_cache(provider_name: str) -> dict[Any, Any]:
    """
    Load the cache for a provider from disk.

    Returns an empty dictionary if no cache exists or if loading fails.
    """
    cache_file = get_cache_dir() / f"{provider_name}.pkl"
    if not cache_file.exists():
        return {}
    try:
        with open(cache_file, "rb") as f:
            return pickle.load(f)
    except (pickle.PickleError, EOFError, OSError):
        return {}
@

Saving is straightforward---we write the dictionary to a pickle file.
We use atomic writes would be safer, but for simplicity we write directly.

<<cache load and save functions>>=
def save_cache(provider_name: str, cache: dict[Any, Any]) -> None:
    """
    Save the cache for a provider to disk.
    """
    cache_file = get_cache_dir() / f"{provider_name}.pkl"
    try:
        with open(cache_file, "wb") as f:
            pickle.dump(cache, f)
    except OSError:
        pass  # Silently fail if we can't write
@

\subsection{Testing load and save}

Caches should round-trip through save and load correctly.

<<test functions>>=
class TestLoadSaveCache:
    """Tests for load_cache and save_cache functions."""

    def test_load_nonexistent_returns_empty(self, tmp_path, monkeypatch):
        """Loading a nonexistent cache returns empty dict."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        result = load_cache("nonexistent")
        assert result == {}

    def test_save_and_load_roundtrip(self, tmp_path, monkeypatch):
        """Saved cache can be loaded back."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        cache = {
            ("query1", 100): [Paper(title="Test", authors=["A"])],
            ("query2", 50): [],
        }
        save_cache("test_provider", cache)
        loaded = load_cache("test_provider")
        assert loaded == cache

    def test_load_corrupted_returns_empty(self, tmp_path, monkeypatch):
        """Loading a corrupted cache file returns empty dict."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        cache_file = tmp_path / "corrupted.pkl"
        cache_file.write_bytes(b"not valid pickle data")
        result = load_cache("corrupted")
        assert result == {}
@


\section{Cache management}

Users need ways to inspect and clear the cache.
We provide functions to get statistics and clear all cached data.

<<cache management functions>>=
def clear_cache() -> int:
    """
    Clear all cached search results.

    Returns the number of cache files deleted.
    """
    cache_dir = get_cache_dir()
    count = 0
    for cache_file in cache_dir.glob("*.pkl"):
        try:
            cache_file.unlink()
            count += 1
        except OSError:
            pass
    return count
@

<<cache management functions>>=
def get_cache_stats() -> dict[str, Any]:
    """
    Return statistics about the cache.

    Returns a dictionary with:
    - cache_dir: Path to the cache directory
    - providers: Dict mapping provider names to entry counts
    - total_entries: Total number of cached queries
    - total_size_bytes: Total size of cache files
    """
    cache_dir = get_cache_dir()
    providers: dict[str, int] = {}
    total_size = 0

    for cache_file in cache_dir.glob("*.pkl"):
        provider_name = cache_file.stem
        total_size += cache_file.stat().st_size
        try:
            cache = load_cache(provider_name)
            providers[provider_name] = len(cache)
        except Exception:
            providers[provider_name] = 0

    return {
        "cache_dir": str(cache_dir),
        "providers": providers,
        "total_entries": sum(providers.values()),
        "total_size_bytes": total_size,
    }
@

\subsection{Testing cache management}

<<test functions>>=
class TestCacheManagement:
    """Tests for cache management functions."""

    def test_clear_cache(self, tmp_path, monkeypatch):
        """clear_cache removes all cache files."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        # Create some cache files
        save_cache("provider1", {"key": "value"})
        save_cache("provider2", {"key": "value"})
        assert len(list(tmp_path.glob("*.pkl"))) == 2
        # Clear them
        count = clear_cache()
        assert count == 2
        assert len(list(tmp_path.glob("*.pkl"))) == 0

    def test_get_cache_stats(self, tmp_path, monkeypatch):
        """get_cache_stats returns accurate information."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        save_cache("provider1", {("q1", 100): [], ("q2", 50): []})
        save_cache("provider2", {("q3", 100): []})
        stats = get_cache_stats()
        assert stats["cache_dir"] == str(tmp_path)
        assert stats["providers"]["provider1"] == 2
        assert stats["providers"]["provider2"] == 1
        assert stats["total_entries"] == 3
        assert stats["total_size_bytes"] > 0
@


\section{Automatic cache persistence}

We want caches to be saved automatically when the program exits.
We maintain a registry of active caches and use [[atexit]] to save them.

<<imports>>=
import atexit
@

<<constants>>=
# Registry of caches to save on exit: provider_name -> cache dict
CACHE_REGISTRY: dict[str, dict[Any, Any]] = {}
@

<<cache management functions>>=
def register_cache(provider_name: str, cache: dict[Any, Any]) -> None:
    """
    Register a cache for automatic persistence on exit.
    """
    CACHE_REGISTRY[provider_name] = cache


def save_all_caches() -> None:
    """
    Save all registered caches to disk.

    Called automatically on program exit.
    """
    for provider_name, cache in CACHE_REGISTRY.items():
        save_cache(provider_name, cache)
@

<<atexit registration>>=
atexit.register(save_all_caches)
@

\subsection{Testing automatic persistence}

<<test functions>>=
class TestAutoPersistence:
    """Tests for automatic cache persistence."""

    def test_register_and_save_all(self, tmp_path, monkeypatch):
        """Registered caches are saved on save_all_caches."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        # Clear any existing registrations
        CACHE_REGISTRY.clear()
        # Register a cache
        cache = {("query", 100): [Paper(title="Test", authors=["A"])]}
        register_cache("test_provider", cache)
        # Save all caches
        save_all_caches()
        # Verify it was saved
        loaded = load_cache("test_provider")
        assert loaded == cache
        # Clean up
        CACHE_REGISTRY.clear()
@


\section{Test Configuration}

The provider tests use caching, which can cause test pollution---cached results
from one test may be returned in another test, causing mock assertions to fail.
We provide a pytest fixture that isolates each test with its own cache directory.

<<[[conftest.py]]>>=
"""Pytest configuration and fixtures for Scholar tests."""
import pytest


@pytest.fixture(autouse=True)
def isolate_cache(tmp_path, monkeypatch):
    """Use a temporary cache directory to prevent cache pollution between tests.

    This fixture is applied automatically to all tests to ensure each test run
    starts with an empty cache and doesn't interfere with other tests.
    """
    cache_dir = tmp_path / "scholar_cache"
    cache_dir.mkdir()
    monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(cache_dir))
@
