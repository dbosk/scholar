\chapter{The Core Module}
\label{scholar-module}

\section{Introduction}

Systematic literature reviews and structured searches are essential for
rigorous academic research.
However, searching across multiple databases---such as Web of Science,
IEEE~Xplore, Semantic~Scholar, and OpenAlex---is tedious and error-prone.
Each database has its own query syntax, interface, and export format.
Reproducing a search requires careful documentation of queries, filters, and
timestamps.

This program, \emph{Scholar}, provides a unified interface for structured
searches across multiple bibliographic databases.
It produces reproducible reports documenting the search process: the queries
used, filters applied, timestamps, and resulting papers.
This supports the transparency required for systematic reviews while reducing
manual effort.

\section{Overall design}

The system consists of several components:
\begin{description}
\item[Search providers] Adapters for different bibliographic databases
  (Semantic~Scholar, OpenAlex, IEEE~Xplore, Web of Science, DBLP, etc.).
\item[Query abstraction] A common query format that translates to
  provider-specific syntax.
\item[Results management] Data structures for papers, with deduplication across
  sources.
\item[Report generation] Tools to export structured, reproducible search
  documentation.
\end{description}

\section{Module structure}

We organize the code as a Python package.
The main module provides the public API:

<<[[scholar.py]]>>=
"""
Scholar: A tool for structured literature searches.

Provides a unified interface for searching bibliographic databases
and generating reproducible search reports.
"""

<<imports>>
<<constants>>
<<classes>>
<<functions>>
@

The package initialization exports the public interface:

<<[[__init__.py]]>>=
"""
Scholar package for structured literature searches.
"""

from .scholar import Search, SearchResult, Paper
from .scholar import search

__all__ = [
    "Search",
    "SearchResult",
    "Paper",
    "search",
]
@


\section{Testing}
\label{sec:testing}

Tests are distributed throughout this document, appearing after each
implementation section they verify.
The test file collects all distributed test chunks:

<<test [[scholar.py]]>>=
"""Tests for the scholar module."""
import pytest
from unittest.mock import Mock

from scholar import *


<<test functions>>
@


\section{Data model}
\label{sec:data-model}

Before implementing search functionality, we establish the data structures that
represent papers and search results.
Getting these abstractions right is crucial: they determine how papers from
different sources are unified and how results can be exported.

\subsection{Why Dataclasses?}

We use Python dataclasses rather than named tuples, dictionaries, or plain
classes because:
\begin{description}
\item[Conciseness] Automatic [[__init__]], [[__repr__]], and [[__eq__]]
  generation reduces boilerplate.
\item[Type hints] Field annotations serve as documentation and enable IDE
  support.
\item[Mutability] Unlike frozen dataclasses or named tuples, we can update
  fields when merging papers from different sources.
\item[Serializability] Works with [[asdict()]] for easy JSON/dict conversion.
\end{description}

\subsection{Representing papers}

A paper has bibliographic metadata that we need for deduplication and export.
Different databases return varying amounts of detail, so we design for the
common core while allowing optional fields:

<<classes>>=
@dataclass
class Paper:
    """Represents a paper from a bibliographic database."""

    title: str
    authors: list[str]
    year: int | None = None
    doi: str | None = None
    abstract: str | None = None
    venue: str | None = None
    url: str | None = None
    pdf_url: str | None = None
    source: str | None = None

    <<paper methods>>
@

We use a dataclass for simplicity.
The [[source]] field tracks which database returned this paper, useful for
provenance in reports.

\subsubsection{Paper identity and deduplication}

When merging results from multiple databases, we need to identify duplicate
papers.
The DOI is the most reliable identifier when available:

<<paper methods>>=
def __eq__(self, other: object) -> bool:
    """Check equality based on DOI if available, else title."""
    if not isinstance(other, Paper):
        return NotImplemented
    if self.doi and other.doi:
        return self.doi.lower() == other.doi.lower()
    return self.title.lower() == other.title.lower()

def __hash__(self) -> int:
    """Hash based on DOI if available, else title."""
    if self.doi:
        return hash(self.doi.lower())
    return hash(self.title.lower())
@

This allows us to use papers in sets for automatic deduplication.

\subsubsection{Consolidating data from multiple sources}

When the same paper appears from multiple providers, each may have different
metadata: one might have an abstract while another has a PDF~URL.
Rather than arbitrarily keeping one version, we consolidate the data to get
the most complete record.

The [[merge_with]] method combines two equal papers (same DOI or title),
keeping non-[[None]] values from either source.
We prefer [[self]]'s values when both have data, since the caller controls
the order of merging.

<<paper methods>>=
def merge_with(self, other: "Paper") -> "Paper":
    """
    Create a consolidated paper from two equal papers.

    Keeps non-None values, preferring self when both have values.
    Combines sources if different.

    Raises:
        ValueError: If papers are not equal (different DOI/title).
    """
    if self != other:
        raise ValueError("Can only merge equal papers")

    # Combine sources for provenance tracking
    sources = []
    if self.source:
        sources.append(self.source)
    if other.source and other.source not in sources:
        sources.append(other.source)

    return Paper(
        title=self.title or other.title,
        authors=self.authors if self.authors else other.authors,
        year=self.year if self.year is not None else other.year,
        doi=self.doi or other.doi,
        abstract=self.abstract or other.abstract,
        venue=self.venue or other.venue,
        url=self.url or other.url,
        pdf_url=self.pdf_url or other.pdf_url,
        source=", ".join(sources) if sources else None,
    )
@

\subsubsection{Testing paper equality}

Let's verify that paper equality and hashing work correctly for deduplication:

<<test functions>>=
class TestPaper:
    """Tests for the Paper class."""

    def test_equality_by_doi(self):
        """Papers with same DOI are equal."""
        p1 = Paper(title="Paper One", authors=["A"], doi="10.1234/test")
        p2 = Paper(title="Paper 1", authors=["B"], doi="10.1234/test")
        assert p1 == p2

    def test_equality_by_title(self):
        """Papers without DOI are equal by title."""
        p1 = Paper(title="Test Paper", authors=["A"])
        p2 = Paper(title="test paper", authors=["B"])
        assert p1 == p2

    def test_inequality(self):
        """Different papers are not equal."""
        p1 = Paper(title="Paper A", authors=["A"])
        p2 = Paper(title="Paper B", authors=["B"])
        assert p1 != p2

    def test_hash_consistency(self):
        """Equal papers have the same hash."""
        p1 = Paper(title="Test", authors=["A"], doi="10.1234/test")
        p2 = Paper(title="Different", authors=["B"], doi="10.1234/test")
        assert hash(p1) == hash(p2)


class TestPaperMergeWith:
    """Tests for Paper.merge_with() consolidation."""

    def test_merge_keeps_abstract_from_other(self):
        """Merging keeps abstract from paper that has it."""
        p1 = Paper(title="Test", authors=["A"], doi="10.1/test", source="dblp")
        p2 = Paper(
            title="Test", authors=["A"], doi="10.1/test",
            abstract="This is the abstract", source="semantic_scholar"
        )
        merged = p1.merge_with(p2)
        assert merged.abstract == "This is the abstract"

    def test_merge_prefers_self_values(self):
        """When both have a value, prefer self."""
        p1 = Paper(
            title="Test", authors=["A"], doi="10.1/test",
            venue="Conference A", source="provider1"
        )
        p2 = Paper(
            title="Test", authors=["A"], doi="10.1/test",
            venue="Conference B", source="provider2"
        )
        merged = p1.merge_with(p2)
        assert merged.venue == "Conference A"

    def test_merge_combines_sources(self):
        """Merging combines sources from both papers."""
        p1 = Paper(title="Test", authors=["A"], source="dblp")
        p2 = Paper(title="test", authors=["B"], source="semantic_scholar")
        merged = p1.merge_with(p2)
        assert "dblp" in merged.source
        assert "semantic_scholar" in merged.source

    def test_merge_raises_for_unequal_papers(self):
        """Cannot merge papers that aren't equal."""
        p1 = Paper(title="Paper A", authors=["A"], doi="10.1/a")
        p2 = Paper(title="Paper B", authors=["B"], doi="10.1/b")
        with pytest.raises(ValueError, match="Can only merge equal papers"):
            p1.merge_with(p2)

    def test_merge_consolidates_all_fields(self):
        """Merging fills in all missing fields from other."""
        p1 = Paper(
            title="Test", authors=["A"], doi="10.1/test",
            year=2024, source="provider1"
        )
        p2 = Paper(
            title="Test", authors=["A"], doi="10.1/test",
            abstract="Abstract", venue="Venue", url="http://example.com",
            pdf_url="http://example.com/pdf", source="provider2"
        )
        merged = p1.merge_with(p2)
        assert merged.year == 2024  # From p1
        assert merged.abstract == "Abstract"  # From p2
        assert merged.venue == "Venue"  # From p2
        assert merged.url == "http://example.com"  # From p2
        assert merged.pdf_url == "http://example.com/pdf"  # From p2
@


\subsection{Search results}

A search result bundles papers with metadata about the search itself, supporting
reproducibility:

<<classes>>=
@dataclass
class SearchResult:
    """Represents the result of a search query."""

    query: str
    provider: str
    timestamp: str
    papers: list[Paper]
    filters: dict | None = None

    <<search result methods>>
@

The [[filters]] dictionary captures any provider-specific constraints (date
ranges, document types, etc.) that were applied.

\subsubsection{Combining results}

We can merge results from multiple searches, deduplicating and consolidating
papers.
When the same paper appears from multiple providers, we consolidate the data
to get the most complete record (keeping abstracts, DOIs, etc.\ from whichever
source has them).

<<search result methods>>=
def merge(self, other: "SearchResult") -> "SearchResult":
    """Merge two search results, deduplicating and consolidating papers."""
    logger.debug(f"Merging search results: {len(self.papers)} + {len(other.papers)} papers")
    
    # Use dict keyed by paper identity to enable consolidation
    paper_map: dict[Paper, Paper] = {}

    for paper in self.papers:
        paper_map[paper] = paper

    duplicates = 0
    for paper in other.papers:
        if paper in paper_map:
            # Consolidate with existing paper
            paper_map[paper] = paper_map[paper].merge_with(paper)
            duplicates += 1
        else:
            paper_map[paper] = paper

    merged_count = len(paper_map)
    logger.info(f"Merged results: {merged_count} unique papers ({duplicates} duplicates removed)")

    return SearchResult(
        query=f"{self.query} | {other.query}",
        provider=f"{self.provider}, {other.provider}",
        timestamp=self.timestamp,
        papers=list(paper_map.values()),
        filters=None,
    )
@

\subsubsection{Testing search results}

The merge operation should deduplicate and consolidate papers:

<<test functions>>=
class TestSearchResult:
    """Tests for the SearchResult class."""

    def test_merge_deduplicates(self):
        """Merging results deduplicates papers."""
        p1 = Paper(title="Paper A", authors=["A"])
        p2 = Paper(title="Paper B", authors=["B"])
        p3 = Paper(title="Paper A", authors=["A"])  # Duplicate of p1

        r1 = SearchResult(
            query="test",
            provider="p1",
            timestamp="2024-01-01",
            papers=[p1, p2],
        )
        r2 = SearchResult(
            query="test",
            provider="p2",
            timestamp="2024-01-01",
            papers=[p2, p3],
        )

        merged = r1.merge(r2)
        assert len(merged.papers) == 2

    def test_merge_consolidates_data(self):
        """Merging consolidates data from duplicate papers."""
        # DBLP paper without abstract
        p1 = Paper(
            title="Paper A", authors=["Author"], doi="10.1/a",
            source="dblp"
        )
        # Semantic Scholar paper with abstract
        p2 = Paper(
            title="Paper A", authors=["Author"], doi="10.1/a",
            abstract="This is the abstract", source="semantic_scholar"
        )

        r1 = SearchResult(
            query="test", provider="dblp",
            timestamp="2024-01-01", papers=[p1]
        )
        r2 = SearchResult(
            query="test", provider="semantic_scholar",
            timestamp="2024-01-01", papers=[p2]
        )

        merged = r1.merge(r2)
        assert len(merged.papers) == 1
        # Consolidated paper should have the abstract
        assert merged.papers[0].abstract == "This is the abstract"
        # And combined sources
        assert "dblp" in merged.papers[0].source
        assert "semantic_scholar" in merged.papers[0].source
@


\subsection{Search abstraction}

The [[Search]] class provides the main interface for conducting searches.
It follows a builder-like pattern: create a [[Search]] object, optionally
configure it, then call [[execute()]] to run the search.

The class accumulates results in [[self.results]], allowing:
\begin{itemize}
\item Multiple calls to [[execute()]] with different provider subsets
\item Inspection of per-provider results before merging
\item Iterative refinement of searches
\end{itemize}

<<classes>>=
class Search:
    """Manages a structured search across bibliographic databases."""

    def __init__(self, query: str):
        """Initialize a search with the given query."""
        self.query = query
        self.results: list[SearchResult] = []

    <<search methods>>
@


\section{Search functionality}

With the data model in place, we implement the search functionality.
For now, we provide a simple interface; provider implementations will be added
as the project develops.

\subsection{Simple search function}

A convenience function for quick searches:

<<functions>>=
def search(query: str) -> SearchResult:
    """
    Perform a simple search and return results.

    This is a convenience function for quick searches.
    For more control, use the Search class directly.
    """
    s = Search(query)
    s.execute()
    return s.results[0] if s.results else SearchResult(
        query=query,
        provider="none",
        timestamp=datetime.now().isoformat(),
        papers=[],
    )
@

\subsection{Executing searches}

The [[Search]] class orchestrates queries across providers.

\subsubsection{Lazy Import Pattern}

We import the provider registry inside [[execute()]] rather than at module
level. This avoids circular imports: [[providers.py]] imports [[Paper]] from
this module, so if we imported [[providers]] here at module level, Python
would encounter an import cycle.

The lazy import pattern has a small runtime cost (import check on each call)
but is negligible compared to API call latency.

<<search methods>>=
def execute(
    self,
    providers: list[str] | None = None,
    limit: int = 100,
) -> list[SearchResult]:
    """
    Execute the search across specified providers.

    Args:
        providers: List of provider names to search. If None, uses the
            default providers (openalex, dblp).
        limit: Maximum number of results per provider.

    Returns:
        List of SearchResult objects, one per provider.
    """
    from scholar.providers import get_provider, get_default_providers

    timestamp = datetime.now().isoformat()

    # Determine which providers to use
    if providers is None:
        provider_list = get_default_providers()
    else:
        provider_list = [
            get_provider(name)
            for name in providers
            if get_provider(name) is not None
        ]

    logger.info(f"Executing search for query: '{self.query}'")
    logger.debug(f"Using {len(provider_list)} provider(s): {[p.name for p in provider_list]}")

    # Query each provider
    for provider in provider_list:
        logger.debug(f"Querying {provider.name} with limit={limit}")
        papers = provider.search(self.query, limit=limit)
        logger.info(f"{provider.name}: Retrieved {len(papers)} papers")
        result = SearchResult(
            query=self.query,
            provider=provider.name,
            timestamp=timestamp,
            papers=papers,
        )
        self.results.append(result)

    logger.info(f"Search complete: {len(self.results)} result set(s)")
    return self.results
@

\subsubsection{Testing the search interface}

The search function should return a valid result:

<<test functions>>=
class TestSearch:
    """Tests for the Search class and search function."""

    def test_search_returns_result(self, monkeypatch):
        """search() returns a SearchResult."""
        from scholar import providers

        mock_provider = Mock()
        mock_provider.name = "mock"
        mock_provider.search.return_value = [
            Paper(title="Test", authors=["Author"])
        ]
        monkeypatch.setattr(providers, "PROVIDERS", {"mock": mock_provider})

        result = search("test query")
        assert isinstance(result, SearchResult)
        assert result.query == "test query"

    def test_search_class_execute(self, monkeypatch):
        """Search.execute() returns results when providers are specified."""
        from scholar import providers

        mock_provider = Mock()
        mock_provider.name = "mock"
        mock_provider.search.return_value = []
        monkeypatch.setattr(providers, "PROVIDERS", {"mock": mock_provider})

        s = Search("test")
        # Explicitly specify the mock provider since "mock" is not a default
        results = s.execute(providers=["mock"])
        assert len(results) > 0
@


\section{Dependencies}

We collect the imports used throughout the module:

<<imports>>=
from dataclasses import dataclass
from datetime import datetime
import logging

logger = logging.getLogger(__name__)
@

<<constants>>=
VERSION = "0.1.0"
@
