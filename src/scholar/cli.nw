\chapter{Command-Line Interface}
\label{cli-module}

\section{Introduction}

This document describes the command-line interface for Scholar.
While the core library (\texttt{scholar.py}) provides the data model and search
functionality, users need a convenient way to invoke searches from the terminal.

The CLI serves several purposes:
\begin{description}
\item[Direct invocation] Users can run searches without writing Python code.
\item[Scripting] The CLI supports output formats suitable for shell pipelines.
\item[Extensibility] The subcommand structure allows adding new functionality
  (like snowball searching) without modifying the core interface.
\end{description}


\section{Design decisions}

We use Typer for the CLI framework because it provides:
\begin{itemize}
\item Automatic help generation from type annotations
\item Subcommand support for modular organization
\item Integration with Rich for formatted output
\end{itemize}

The CLI is organized as subcommands to prepare for future extensions.
Currently, we have the [[search]] command; later we will add [[snowball]] and
[[tuxedo]] as git submodules that register their own commands.


\section{Module structure}

The CLI module provides the main entry point:

<<[[cli.py]]>>=
"""
Scholar command-line interface.

Provides commands for structured literature searches
across bibliographic databases.
"""

<<cli imports>>
<<constants>>
<<output formatters>>
<<typer application>>
<<search command>>
<<providers command>>
<<cache command>>
<<submodule registration>>
<<main entry point>>
@

We also provide a [[__main__.py]] module so users can run Scholar with
[[python -m scholar]]:

<<[[__main__.py]]>>=
"""Allow running Scholar as a module: python -m scholar"""
from scholar.cli import main

if __name__ == "__main__":
    main()
@


\chapter{The Typer Application}

We create a Typer application that serves as the root for all subcommands.
The [[no_args_is_help=True]] setting ensures users see help when they run
[[scholar]] without arguments.

To ensure proper subcommand behavior (where users must type [[scholar search]]
rather than just [[scholar]]), we add a callback to the main app.
Without this callback, Typer treats a single command as the default and
absorbs its arguments into the main app.

<<typer application>>=
app = typer.Typer(
    name="scholar",
    help="Structured literature search tool for systematic reviews.",
    no_args_is_help=True,
)


@app.callback()
def callback() -> None:
    """
    Scholar: A tool for structured literature searches.

    Use 'scholar search' to query bibliographic databases.
    """
    pass
@


\chapter{The Search Command}

The primary command is [[search]], which queries bibliographic databases and
displays results.
We use Typer's [[Annotated]] syntax for clean argument definitions.

<<search command>>=
@app.command()
def search(
    query: Annotated[str, typer.Argument(help="Search query string")],
    <<search command options>>
) -> None:
    """
    Search bibliographic databases with structured queries.

    Queries all available providers by default. Use -p to select specific ones.

    Examples:
        scholar search "machine learning privacy"
        scholar search "federated learning" -p semantic_scholar -f json
    """
    <<execute search and display results>>
@

\section{Command options}

The search command accepts options for controlling which providers to query
and how to format output:

<<search command options>>=
provider: Annotated[
    Optional[list[str]],
    typer.Option(
        "--provider", "-p",
        help="Provider to query. Repeatable. Default: all providers.",
    ),
] = None,
output_format: Annotated[
    str,
    typer.Option(
        "--format", "-f",
        help="Output format: auto, table, csv, json, or bibtex. "
             "Auto selects table for TTY, csv otherwise.",
    ),
] = "auto",
review: Annotated[
    bool,
    typer.Option(
        "--review", "-r",
        help="Launch interactive TUI to review and filter results.",
    ),
] = False
@

\section{Executing the search}

We import the [[Search]] class from the core module and execute the query.
The results are then passed to the appropriate formatter:

<<execute search and display results>>=
from scholar import Search
import sys

s = Search(query)
results = s.execute(providers=provider)

# If review mode, launch TUI instead of displaying results
if review:
    from scholar.tui import run_review
    run_review(results, query)
    return

# Auto-detect format based on TTY
actual_format = output_format
if output_format == "auto":
    actual_format = "table" if sys.stdout.isatty() else "csv"

display_results(results, actual_format)
@


\chapter{Listing Available Providers}

Users need to know which search providers are available and how to configure
them.
Rather than requiring users to read the literate documentation, we provide a
[[providers]] command that displays this information directly.

<<providers command>>=
@app.command()
def providers() -> None:
    """
    List available search providers and their configuration.

    Shows which providers require API keys and how to obtain them.
    """
    <<display provider information>>
@

We organize provider information in a table showing the provider name,
whether an API key is required, and the environment variable to set:

<<display provider information>>=
from scholar.providers import get_all_providers

console = Console()

table = Table(title="Available Search Providers")
table.add_column("Provider", style="cyan")
table.add_column("API Key", style="yellow")
table.add_column("Environment Variable", style="green")
table.add_column("How to Get Key", style="dim")

<<add provider rows to table>>

console.print(table)
console.print()
console.print("[dim]Providers without API keys work immediately.[/dim]")
console.print(
    "[dim]Set environment variables to enable key-required providers.[/dim]"
)
@

We define the configuration details for each provider.
This information is kept here rather than in the provider classes because
it is user-facing documentation, not implementation details:

<<add provider rows to table>>=
provider_info = {
    "semantic_scholar": {
        "required": False,
        "env_var": "S2_API_KEY",
        "how_to_get": "api.semanticscholar.org (optional, higher rate limits)",
    },
    "openalex": {
        "required": False,
        "env_var": "OPENALEX_EMAIL",
        "how_to_get": "Any email (optional, faster responses)",
    },
    "dblp": {
        "required": False,
        "env_var": "-",
        "how_to_get": "No key needed",
    },
    "wos": {
        "required": True,
        "env_var": "WOS_API_KEY",
        "how_to_get": "developer.clarivate.com",
    },
    "ieee": {
        "required": True,
        "env_var": "IEEE_API_KEY",
        "how_to_get": "developer.ieee.org",
    },
}

for provider in get_all_providers():
    info = provider_info.get(provider.name, {})
    required = info.get("required", False)
    key_status = "[red]Required[/red]" if required else "[green]Optional[/green]"
    table.add_row(
        provider.name,
        key_status,
        info.get("env_var", "-"),
        info.get("how_to_get", ""),
    )
@


\chapter{Cache Management}

Search results are cached to avoid redundant API calls.
Users can inspect and manage the cache using the [[cache]] command.

<<cache command>>=
@app.command()
def cache(
    action: Annotated[
        str,
        typer.Argument(help="Action: clear, info, or path"),
    ],
) -> None:
    """
    Manage the search result cache.

    Actions:
        clear  - Delete all cached search results
        info   - Show cache statistics (entries, size, location)
        path   - Print the cache directory path
    """
    from scholar.cache import clear_cache, get_cache_stats

    console = Console()

    if action == "clear":
        count = clear_cache()
        console.print(f"Cleared {count} cached provider(s).")

    elif action == "info":
        stats = get_cache_stats()
        table = Table(title="Cache Statistics")
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")

        table.add_row("Location", stats["cache_dir"])
        table.add_row("Total entries", str(stats["total_entries"]))
        size_kb = stats["total_size_bytes"] / 1024
        table.add_row("Total size", f"{size_kb:.1f} KB")

        console.print(table)

        if stats["providers"]:
            console.print()
            provider_table = Table(title="Entries per Provider")
            provider_table.add_column("Provider", style="cyan")
            provider_table.add_column("Cached queries", justify="right")

            for provider_name, count in sorted(stats["providers"].items()):
                provider_table.add_row(provider_name, str(count))

            console.print(provider_table)

    elif action == "path":
        stats = get_cache_stats()
        print(stats["cache_dir"])

    else:
        console.print(f"[red]Unknown action: {action}[/red]")
        console.print("Valid actions: clear, info, path")
        raise typer.Exit(1)
@


\chapter{Output Formatting}

Different use cases require different output formats:
\begin{description}
\item[table] Human-readable Rich tables for interactive use.
\item[json] Machine-readable format for scripting and pipelines.
\item[bibtex] Citation format for integration with \LaTeX{} documents.
\end{description}

We implement a formatter for each and dispatch based on the user's choice.

\section{The display function}

This function selects the appropriate formatter and invokes it:

<<output formatters>>=
<<formatter classes>>

FORMATTERS: dict[str, type] = {
    "table": TableFormatter,
    "csv": CSVFormatter,
    "json": JSONFormatter,
    "bibtex": BibTeXFormatter,
}


def display_results(results: list, output_format: str = "table") -> None:
    """
    Display search results in the specified format.

    Args:
        results: List of SearchResult objects to display.
        output_format: One of 'table', 'csv', 'json', or 'bibtex'.
    """
    formatter_class = FORMATTERS.get(output_format, TableFormatter)
    formatter = formatter_class()
    formatter.format(results)
@


\section{Table formatter}

The table formatter uses Rich to create visually appealing output.
We show the query and provider as context, then list papers with key metadata:

<<formatter classes>>=
class TableFormatter:
    """Display results as Rich tables."""

    def __init__(self) -> None:
        self.console = Console()

    def format(self, results: list) -> None:
        """Display results in formatted tables."""
        for result in results:
            table = Table(
                title=f"Results for: {result.query}",
                caption=f"Provider: {result.provider} | {result.timestamp}",
            )

            table.add_column("Title", style="cyan", no_wrap=False)
            table.add_column("Authors", style="green")
            table.add_column("Year", justify="right")
            table.add_column("DOI", style="dim")

            for paper in result.papers:
                authors = ", ".join(paper.authors[:3])
                if len(paper.authors) > 3:
                    authors += "..."
                table.add_row(
                    paper.title,
                    authors,
                    str(paper.year) if paper.year else "",
                    paper.doi or "",
                    end_section=True,
                )

            self.console.print(table)

            if not result.papers:
                self.console.print("[dim]No results found.[/dim]")
@


\section{CSV formatter}

For scripting and shell pipelines, we provide a tab-separated CSV format.
This is especially useful when output is piped to other commands.
We include metadata as a comment header so consumers know the search context:

<<formatter classes>>=
class CSVFormatter:
    """Output results as tab-separated values for scripting."""

    def format(self, results: list) -> None:
        """Output results as CSV with metadata header."""
        for result in results:
            # Metadata header as comments
            print(f"# Query: {result.query}")
            print(f"# Provider: {result.provider}")
            print(f"# Timestamp: {result.timestamp}")
            print(f"# Results: {len(result.papers)}")
            print()

            # Header row
            print("title\tauthors\tyear\tdoi\tvenue\turl")

            # Data rows
            for paper in result.papers:
                authors = "; ".join(paper.authors)
                year = str(paper.year) if paper.year else ""
                print(f"{paper.title}\t{authors}\t{year}\t"
                      f"{paper.doi or ''}\t{paper.venue or ''}\t"
                      f"{paper.url or ''}")
            print()
@


\section{JSON formatter}

For scripting, we provide JSON output that includes all paper metadata:

<<formatter classes>>=
class JSONFormatter:
    """Output results as JSON for scripting."""

    def format(self, results: list) -> None:
        """Output results as JSON."""
        output = []
        for result in results:
            output.append({
                "query": result.query,
                "provider": result.provider,
                "timestamp": result.timestamp,
                "papers": [
                    {
                        "title": p.title,
                        "authors": p.authors,
                        "year": p.year,
                        "doi": p.doi,
                        "abstract": p.abstract,
                        "venue": p.venue,
                        "url": p.url,
                    }
                    for p in result.papers
                ],
            })
        print(json.dumps(output, indent=2))
@


\section{BibTeX formatter}

For \LaTeX{} users, we generate BibTeX entries that can be added to a
[[.bib]] file:

<<formatter classes>>=
class BibTeXFormatter:
    """Output results as BibTeX entries."""

    def format(self, results: list) -> None:
        """Output results as BibTeX."""
        for result in results:
            for paper in result.papers:
                self._format_paper(paper)

    def _format_paper(self, paper) -> None:
        """Format a single paper as BibTeX."""
        first_author = (
            paper.authors[0].split()[-1] if paper.authors else "unknown"
        )
        year = paper.year or "nd"
        key = f"{first_author.lower()}{year}"

        print(f"@article{{{key},")
        print(f"  title = {{{paper.title}}},")
        print(f"  author = {{{' and '.join(paper.authors)}}},")
        if paper.year:
            print(f"  year = {{{paper.year}}},")
        if paper.doi:
            print(f"  doi = {{{paper.doi}}},")
        if paper.venue:
            print(f"  journal = {{{paper.venue}}},")
        print("}")
        print()
@

\section{Testing formatters}

We test each formatter with sample data:

<<test formatters>>=
class TestFormatters:
    """Tests for output formatters."""

    @pytest.fixture
    def sample_results(self):
        """Create sample search results for testing."""
        papers = [
            Paper(
                title="Test Paper",
                authors=["Alice", "Bob"],
                year=2024,
                doi="10.1234/test",
            ),
        ]
        return [
            SearchResult(
                query="test",
                provider="test_provider",
                timestamp="2024-01-01T00:00:00",
                papers=papers,
            )
        ]

    def test_table_formatter(self, sample_results, capsys):
        """TableFormatter produces output."""
        formatter = TableFormatter()
        formatter.format(sample_results)
        captured = capsys.readouterr()
        assert "Test Paper" in captured.out

    def test_json_formatter(self, sample_results, capsys):
        """JSONFormatter produces valid JSON."""
        formatter = JSONFormatter()
        formatter.format(sample_results)
        captured = capsys.readouterr()
        import json
        data = json.loads(captured.out)
        assert data[0]["query"] == "test"
        assert data[0]["papers"][0]["title"] == "Test Paper"

    def test_bibtex_formatter(self, sample_results, capsys):
        """BibTeXFormatter produces BibTeX entries."""
        formatter = BibTeXFormatter()
        formatter.format(sample_results)
        captured = capsys.readouterr()
        assert "@article{" in captured.out
        assert "title = {Test Paper}" in captured.out
@


\chapter{Submodule Registration}

To support future extensions like snowball and tuxedo, we provide a mechanism
for submodules to register their commands with the main application.

Each submodule should provide a [[register_commands(app)]] function that adds
its commands to the Typer app.
We attempt to import each known submodule and call this function if it exists:

<<submodule registration>>=
SUBMODULES = ["snowball", "tuxedo"]


def register_submodules() -> None:
    """
    Dynamically register subcommand modules if available.

    This allows snowball and tuxedo to be added as git submodules
    without modifying this file. Each submodule should provide a
    `register_commands(app)` function.
    """
    for name in SUBMODULES:
        try:
            module = __import__(f"scholar.{name}", fromlist=["register_commands"])
            if hasattr(module, "register_commands"):
                module.register_commands(app)
        except ImportError:
            pass  # Submodule not installed
@


\chapter{Entry Point}

The main entry point registers any available submodules and then runs the
Typer application:

<<main entry point>>=
def main() -> None:
    """Main entry point for the Scholar CLI."""
    register_submodules()
    app()
@

\section{Testing the CLI application}

We use Typer's [[CliRunner]] to test the CLI without actually invoking
a subprocess:

<<test cli>>=
runner = CliRunner()


class TestCLI:
    """Tests for the CLI application."""

    def test_help_displayed(self):
        """Running without args shows help with 'search' command listed."""
        result = runner.invoke(app, [])
        # Exit code 2 is expected (no command given), but help should show
        assert "search" in result.stdout
        assert "Commands" in result.stdout

    def test_explicit_help(self):
        """Running with --help shows help with exit code 0."""
        result = runner.invoke(app, ["--help"])
        assert result.exit_code == 0
        assert "search" in result.stdout

    def test_search_command_exists(self):
        """The search command is registered."""
        result = runner.invoke(app, ["search", "--help"])
        assert result.exit_code == 0
        assert "Search bibliographic databases" in result.stdout

    def test_search_runs(self, monkeypatch):
        """Search command executes without error."""
        # Mock the provider to avoid real API calls
        from scholar import providers

        mock_provider = Mock()
        mock_provider.name = "mock"
        mock_provider.search.return_value = []
        monkeypatch.setattr(providers, "PROVIDERS", {"mock": mock_provider})

        result = runner.invoke(app, ["search", "test query"])
        assert result.exit_code == 0

    def test_providers_command_exists(self):
        """The providers command is registered."""
        result = runner.invoke(app, ["providers", "--help"])
        assert result.exit_code == 0
        assert "List available search providers" in result.stdout

    def test_providers_lists_providers(self):
        """The providers command lists available providers."""
        result = runner.invoke(app, ["providers"])
        assert result.exit_code == 0
        # Should show at least these providers
        assert "semantic_scholar" in result.stdout
        assert "openalex" in result.stdout
        assert "dblp" in result.stdout

    def test_providers_shows_api_info(self):
        """The providers command shows API key information."""
        result = runner.invoke(app, ["providers"])
        assert result.exit_code == 0
        # Should show environment variable names
        assert "S2_API_KEY" in result.stdout
        assert "WOS_API_KEY" in result.stdout
        assert "IEEE_API_KEY" in result.stdout

    def test_cache_command_exists(self):
        """The cache command is registered."""
        result = runner.invoke(app, ["cache", "--help"])
        assert result.exit_code == 0
        assert "Manage the search result cache" in result.stdout

    def test_cache_info(self, tmp_path, monkeypatch):
        """Cache info shows statistics."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        result = runner.invoke(app, ["cache", "info"])
        assert result.exit_code == 0
        assert "Location" in result.stdout
        assert "Total entries" in result.stdout

    def test_cache_clear(self, tmp_path, monkeypatch):
        """Cache clear removes cache files."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        # Create a dummy cache file
        (tmp_path / "test.pkl").touch()
        result = runner.invoke(app, ["cache", "clear"])
        assert result.exit_code == 0
        assert "Cleared" in result.stdout

    def test_cache_path(self, tmp_path, monkeypatch):
        """Cache path prints directory."""
        monkeypatch.setenv("SCHOLAR_CACHE_DIR", str(tmp_path))
        result = runner.invoke(app, ["cache", "path"])
        assert result.exit_code == 0
        assert str(tmp_path) in result.stdout

    def test_cache_invalid_action(self):
        """Cache with invalid action shows error."""
        result = runner.invoke(app, ["cache", "invalid"])
        assert result.exit_code == 1
        assert "Unknown action" in result.stdout
@


\chapter{Dependencies}

We collect the imports used throughout the module:

<<cli imports>>=
from typing import Optional
from typing_extensions import Annotated
import json

import typer
from rich.console import Console
from rich.table import Table
@

<<constants>>=
# CLI constants (reserved for future use)
@


\chapter{Tests}
\label{ch:cli-testing}

Tests are distributed throughout this document, appearing after each
implementation section they verify.
The test file collects all distributed test chunks:

<<test [[cli.py]]>>=
"""Tests for the CLI module."""
import pytest
from unittest.mock import Mock
from typer.testing import CliRunner

from scholar.cli import app, TableFormatter, JSONFormatter, BibTeXFormatter
from scholar import SearchResult, Paper


<<test cli>>
<<test formatters>>
@
